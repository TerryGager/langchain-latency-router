# langchain-latency-router
Dynamically route LangChain prompts to the fastest LLM provider using real-time benchmarking from InferenceLatency.com
